\documentclass[10pt, conference, letterpaper]
{IEEEtran}

\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[ansinew]{inputenc} 
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{import}
\usepackage{multirow}
\usepackage{cite}
\usepackage[export]{adjustbox}
\usepackage{breqn}
\usepackage{mathrsfs}
\usepackage{acronym}
%\usepackage[keeplastbox]{flushend}
\usepackage{setspace}
\usepackage{bm}
\usepackage{stackengine}
\usepackage{float}
\usepackage{listings}
\usepackage{url}
\usepackage{hyperref}

\lstset{%
 backgroundcolor=\color[gray]{.85},
 basicstyle=\small\ttfamily,
 breaklines = true,
 keywordstyle=\color{red!75},
 columns=fullflexible,
}%

\lstdefinelanguage{BibTeX}
  {keywords={%
      @article,@book,@collectedbook,@conference,@electronic,@ieeetranbstctl,%
      @inbook,@incollectedbook,@incollection,@injournal,@inproceedings,%
      @manual,@mastersthesis,@misc,@patent,@periodical,@phdthesis,@preamble,%
      @proceedings,@standard,@string,@techreport,@unpublished%
      },
   comment=[l][\itshape]{@comment},
   sensitive=false,
  }

\usepackage{listings}

% listings settings from classicthesis package by
% Andr\'{e} Miede
\lstset{language=[LaTeX]Tex,%C++,
    keywordstyle=\color{RoyalBlue},%\bfseries,
    basicstyle=\small\ttfamily,
    %identifierstyle=\color{NavyBlue},
    commentstyle=\color{Green}\ttfamily,
    stringstyle=\rmfamily,
    numbers=none,%left,%
    numberstyle=\scriptsize,%\tiny
    stepnumber=5,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frameround=ftff,
    frame=single
    %frame=L
}

\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\thesubtable}{\alph{subtable}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\def\delequal{\mathrel{\ensurestackMath{\stackon[1pt]{=}{\scriptscriptstyle\Delta}}}}

\graphicspath{{./figures/}}
\setlength{\belowcaptionskip}{0mm}
\setlength{\textfloatsep}{8pt}

\newcommand{\eq}[1]{Eq.~\eqref{#1}}
\newcommand{\fig}[1]{Fig.~\ref{#1}}
\newcommand{\tab}[1]{Tab.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}

\newcommand\MR[1]{\textcolor{blue}{#1}}
\newcommand\red[1]{\textcolor{red}{#1}}
\newcommand{\mytexttilde}{{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}}

%\renewcommand{\baselinestretch}{0.98}
% \renewcommand{\bottomfraction}{0.8}
% \setlength{\abovecaptionskip}{0pt}
\setlength{\columnsep}{0.2in}

% \IEEEoverridecommandlockouts\IEEEpubid{\makebox[\columnwidth]{PUT COPYRIGHT NOTICE HERE \hfill} \hspace{\columnsep}\makebox[\columnwidth]{ }} 

\title{Lightweight keyword spotting using attention-based recurrent neural networks}

\author{Matteo Moratello$^\dag$, Enrico Petrucci$^\ddag$
\thanks{$^\dag$Department of Information Engineering, University of Padova, email: moratellom@dei.unipd.it}
\thanks{$^\ddag$Department of Information Engineering, University of Padova, email: petruccien@dei.unipd.it}
} 

\IEEEoverridecommandlockouts

\newcounter{remark}[section]
\newenvironment{remark}[1][]{\refstepcounter{remark}\par\medskip
   \textbf{Remark~\thesection.\theremark. #1} \rmfamily}{\medskip}

\begin{document}

\maketitle

\begin{abstract}
The problem of Keyword Spotting (KWS) has been gaining relevance in recent years due to the increasing spread of voice controlled devices. These kinds of devices require high accuracy models in order to be reliable enough, but a small footprint because of their limited power and hardware capabilities.
In this paper we investigate two learning architectures to address this problem and propose new models: recurrent neural networks -- that use the attention mechanism -- and residual neural networks.
Our best recurrent neural networks can outperform the previous state-of-the-art models while having fewer parameters. The most accurate model that we found has an accuracy of 97.1\% while having 155K parameters.  We also present a lightweight model that only has 25K parameters -- a fraction of the usual amount -- but manages to perform comparably and sometimes even better than larger models in the literature, reaching an accuracy of 96.6\%.
Even our ResNet models manage to surpass, in terms of performance, the previous models that were based on this kind of architecture. We show detailed comparisons between our new models and the best models in previous literature.
These kinds of high accuracy, but small-footprint models are crucial for delivering less expensive and reliable devices.\\ 
\end{abstract}

\IEEEkeywords
Command Recognition, Keyword Spotting, Recurrent Neural Network, Residual Neural Network, Attention
\endIEEEkeywords


\input{intro}

\input{related}

\input{model}

\input{results}

\input{conclusions}

\bibliography{biblio}
\bibliographystyle{ieeetr}

\end{document}


